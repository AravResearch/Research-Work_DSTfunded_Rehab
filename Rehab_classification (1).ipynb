{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rehab_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84sfti6ul240"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.datasets import make_classification\n",
        "RANDOM_STATE = 8\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing and Splitting the dataset\n",
        "dataset = pd.read_csv('after_fe.csv')\n",
        "df = dataset.iloc[ : , :]\n",
        "#print(df.head())\n",
        "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
        "#print(X)\n",
        "#print(y)"
      ],
      "metadata": {
        "id": "crJda-KMs2m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "tdL1gvdUs63a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.common import random_state\n",
        "for model in [LogisticRegression(random_state=RANDOM_STATE), RandomForestClassifier(random_state=RANDOM_STATE), MLPClassifier(max_iter=10000,random_state=RANDOM_STATE), XGBClassifier(),GradientBoostingClassifier(random_state=RANDOM_STATE), svm.SVC(), DecisionTreeClassifier(random_state=RANDOM_STATE),BaggingClassifier(n_estimators=50), AdaBoostClassifier(n_estimators=100)]:\n",
        "    \n",
        "    print(\"[INFO]: Fitting\", str(model), \"...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6Cevhybs8uH",
        "outputId": "6f3fa5d3-f635-44c4-e723-33ef17dd016e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Fitting LogisticRegression(random_state=8) ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.83        12\n",
            "   macro avg       0.83      0.83      0.83        12\n",
            "weighted avg       0.83      0.83      0.83        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting RandomForestClassifier(random_state=8) ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77         7\n",
            "           1       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.75        12\n",
            "   macro avg       0.75      0.76      0.75        12\n",
            "weighted avg       0.76      0.75      0.75        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting MLPClassifier(max_iter=10000, random_state=8) ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77         7\n",
            "           1       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.75        12\n",
            "   macro avg       0.75      0.76      0.75        12\n",
            "weighted avg       0.76      0.75      0.75        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting XGBClassifier() ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.83        12\n",
            "   macro avg       0.83      0.83      0.83        12\n",
            "weighted avg       0.83      0.83      0.83        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting GradientBoostingClassifier(random_state=8) ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.83        12\n",
            "   macro avg       0.83      0.83      0.83        12\n",
            "weighted avg       0.83      0.83      0.83        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting SVC() ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.86      0.75         7\n",
            "           1       0.67      0.40      0.50         5\n",
            "\n",
            "    accuracy                           0.67        12\n",
            "   macro avg       0.67      0.63      0.62        12\n",
            "weighted avg       0.67      0.67      0.65        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting DecisionTreeClassifier(random_state=8) ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.67         7\n",
            "           1       0.50      0.40      0.44         5\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.56      0.56      0.56        12\n",
            "weighted avg       0.57      0.58      0.57        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting BaggingClassifier(n_estimators=50) ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77         7\n",
            "           1       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.75        12\n",
            "   macro avg       0.75      0.76      0.75        12\n",
            "weighted avg       0.76      0.75      0.75        12\n",
            " \n",
            "\n",
            "[INFO]: Fitting AdaBoostClassifier(n_estimators=100) ...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92         7\n",
            "           1       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.92        12\n",
            "   macro avg       0.92      0.93      0.92        12\n",
            "weighted avg       0.93      0.92      0.92        12\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AdaBoostClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSIawQp16FwT",
        "outputId": "e0db616e-01c1-404b-dca1-c44e1bac405d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 1]\n",
            " [0 5]]\n"
          ]
        }
      ]
    }
  ]
}